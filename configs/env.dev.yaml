project_id: "lakehouse-486419"
region: "europe-west1"
env: "dev"

buckets:
  scripts: "lakehouse-486419-scripts-dev"
  iceberg: "lakehouse-486419-iceberg-dev"
  dataproc_temp: "lakehouse-lakehouse-486419-dataproc-temp-dev"   # <-- AJOUTE CE BUCKET

iceberg:
  warehouse_uri: "gs://lakehouse-486419-iceberg-dev/warehouse"
  catalog_name: "lakehouse"
  db: "curated_iceberg_dev"
  table: "sample_ext"
  raw_table: "raw_ext_dev.sample_ext"

dataproc:
  runtime_version: "2.2"
  service_account: "sa-dataproc-dev@lakehouse-486419.iam.gserviceaccount.com"
  scala_binary: "2.13"   # <-- IMPORTANT : 2.12 OU 2.13 selon diag
  iceberg_package: "org.apache.iceberg:iceberg-spark-runtime-3.5_2.13:1.6.1"
  # bigquery_package: "com.google.cloud.spark:spark-bigquery-with-dependencies_2.13:0.36.4"  # optionnel
  dataproc_temp: "lakehouse-lakehouse-486419-dataproc-temp-dev"

gcp:
  project_id: "lakehouse-dev-486419"
  region: "europe-west1"

dataform:
  repo: "lakehouse-dev-dataform"          # <-- nom du repo Dataform dans GCP
  workflow: "wf-dev-weekdays"             # <-- nom du workflow config dans GCP

gcs:
  raw_bucket: lakehouse-486419-raw-dev

